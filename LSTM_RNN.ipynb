{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = pd.read_csv('training_set.csv')\n",
    "metadata_train = pd.read_csv('training_set_metadata.csv')\n",
    "\n",
    "simple_features = train_series.groupby(\n",
    "    ['object_id', 'passband'])['flux'].agg(\n",
    "    ['mean', 'median', 'max', 'min', 'std']).unstack('passband')\n",
    "\n",
    "\n",
    "#construct time series using binned observations:\n",
    "ts_mod = train_series[['object_id', 'mjd', 'passband', 'flux']].copy()\n",
    "#bin by 5 days, reducing the size of data but still giving a time series\n",
    "ts_mod['mjd_d5'] = (ts_mod['mjd'] / 5).astype(int)\n",
    "ts_mod = ts_mod.groupby(['object_id', 'mjd_d5', 'passband'])['flux'].mean().reset_index()\n",
    "\n",
    "#pivotting\n",
    "ts_piv = pd.pivot_table(ts_mod, \n",
    "                        index='object_id', \n",
    "                        columns=['mjd_d5', 'passband'], \n",
    "                        values=['flux'],\n",
    "                        dropna=False)\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del metadata_train['ra'],metadata_train['decl'],metadata_train['gal_l'], metadata_train['gal_b'],metadata_train['hostgal_photoz'],metadata_train['hostgal_photoz_err'], metadata_train['distmod'], metadata_train['mwebv']\n",
    "#Bin into ddf and non-ddf training\n",
    "ddf = metadata_train[(metadata_train['ddf'] == 1)]\n",
    "del ddf['ddf']\n",
    "\n",
    "ddf_far_away= (ddf[(ddf['hostgal_specz'] > 0)])\n",
    "ddf_far_away.set_index('object_id', inplace=True)\n",
    "ddf_nearby= ddf[(ddf['hostgal_specz'] <=0)]\n",
    "ddf_nearby.set_index('object_id', inplace=True)\n",
    "non_ddf = metadata_train[(metadata_train['ddf'] == 0)]\n",
    "del non_ddf['ddf']\n",
    "\n",
    "non_ddf_far_away= non_ddf[(non_ddf['hostgal_specz'] >0)]\n",
    "non_ddf_far_away.set_index('object_id', inplace=True)\n",
    "non_ddf_nearby= non_ddf[(non_ddf['hostgal_specz'] <=0 )]\n",
    "non_ddf_nearby.set_index('object_id', inplace=True)\n",
    "del ddf, non_ddf, ddf_far_away['hostgal_specz'], non_ddf_far_away['hostgal_specz'], ddf_nearby['hostgal_specz'], non_ddf_nearby['hostgal_specz']\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "bins = [ddf_far_away, ddf_nearby, non_ddf_far_away, non_ddf_nearby]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_point(object_id, bin_name):\n",
    "    x = torch.tensor(ts_piv.loc[object_id].values.reshape(-1, 1, 6), dtype = torch.float32)\n",
    "    x[x != x] = 0\n",
    "    y = torch.tensor([classes.index(bin_name.loc[object_id].values)])\n",
    "    return x, y\n",
    "\n",
    "def random_data_point(bin_name):\n",
    "    object_id = bin_name.sample().index.values[0]\n",
    "    return get_data_point(object_id, bin_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        #TODO add dropout or something\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size) #,dropout=.2, num_layers=2)\n",
    "        self.hidden2out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        x = sequence.view(len(sequence), self.batch_size , -1)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        output  = self.hidden2out(lstm_out[-1])\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(1, self.batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(metadata_train.target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return classes[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(6, 32, 14)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: (62, 8), Actual: (92, 0)\n",
      "Epoch 1 0.0% ===> Avg Loss: 0.0024833115749061108\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x, y = random_data_point(non_ddf_far_away)\n",
    "    y_hat = model(x)\n",
    "    print(\"Predicted: {}, Actual: {}\".format(categoryFromOutput(y_hat), categoryFromOutput(y)))\n",
    "\n",
    "    \n",
    "print_every = 100\n",
    "all_data_points = len(non_ddf_far_away.index)\n",
    "current_loss = 0\n",
    "\n",
    "for epoch in range(1):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for i, obj_id in enumerate(non_ddf_far_away.index):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        x_train, y_train = get_data_point(obj_id, non_ddf_far_away)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        y_hat = model(x_train)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        current_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(f\"Epoch {epoch+1} {i/all_data_points*100}%\")\n",
    "        \n",
    "        if (i % print_every == 0):\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} {i/all_data_points*100}% ===> Avg Loss: {current_loss/1000}\")\n",
    "            current_loss=0\n",
    "        if i == 50:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "correct = 0\n",
    "sample = 100\n",
    "for i in range(sample):\n",
    "    obj = random.choice(ddf_far_away.index)\n",
    "    x, y = get_data_point(obj, ddf_far_away)\n",
    "    y_hat = model(x)\n",
    "    label = categoryFromOutput(y_hat)[0]\n",
    "    if classes[y]==label:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy: {correct/sample*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65    57.222222\n",
       "16    30.000000\n",
       "92    10.740741\n",
       "6      1.296296\n",
       "53     0.740741\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_nearby[\"target\"].value_counts(normalize=True) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
